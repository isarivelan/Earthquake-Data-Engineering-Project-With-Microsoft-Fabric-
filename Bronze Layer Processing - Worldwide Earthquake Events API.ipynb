{"cells":[{"cell_type":"markdown","source":["# <mark></mark>Bronze Layer Processing - Worldwide Earthquake Events API "],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"81d6b708-49b8-4098-af28-63c043e0c4f5"},{"cell_type":"code","source":["import requests\n","import json\n","\n","# Construct the API URL with start and end dates provided by Data Factory, formatted for geojson output.\n","url = f\"https://earthquake.usgs.gov/fdsnws/event/1/query?format=geojson&starttime={start_date}&endtime={end_date}\"\n","\n","# Make the GET request to fetch data\n","response = requests.get(url)\n","\n","# Check if the request was successful\n","if response.status_code == 200:\n","    # Get the JSON response\n","    data = response.json()\n","    data = data['features']\n","    \n","    # Specify the file name (and path if needed)\n","    file_path = f'/lakehouse/default/Files/{start_date}_earthquake_data.json'\n","    \n","    # Open the file in write mode ('w') and save the JSON data\n","    with open(file_path, 'w') as file:\n","        # The `json.dump` method serializes `data` as a JSON formatted stream to `file`\n","        # `indent=4` makes the file human-readable by adding whitespace\n","        json.dump(data, file, indent=4)\n","        \n","    print(f\"Data successfully saved to {file_path}\")\n","else:\n","    print(\"Failed to fetch data. Status code:\", response.status_code)"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":6,"statement_ids":[6],"state":"finished","livy_statement_state":"available","session_id":"4c53dc58-b543-4f01-8716-d971c03493f5","normalized_state":"finished","queued_time":"2024-11-08T08:16:41.8288943Z","session_start_time":null,"execution_start_time":"2024-11-08T08:16:43.0933845Z","execution_finish_time":"2024-11-08T08:16:45.5777439Z","parent_msg_id":"cea13cad-e9bf-4a7c-bfba-ad53201c63d8"},"text/plain":"StatementMeta(, 4c53dc58-b543-4f01-8716-d971c03493f5, 6, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Data successfully saved to /lakehouse/default/Files/2024-11-01_earthquake_data.json\n"]}],"execution_count":4,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"1d6b3c33-bb83-49ed-9f67-3cbfbd268a4a"},{"cell_type":"code","source":["df = spark.read.option(\"multiline\", \"true\").json(\"Files/2024-11-01_earthquake_data.json\")\n","# df now is a Spark DataFrame containing JSON data from \"Files/2024-11-01_earthquake_data.json\".\n","display(df)"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"collapsed":false},"id":"7be3083e-39d6-4beb-bf7a-82c05b115b4f"}],"metadata":{"language_info":{"name":"python"},"kernel_info":{"name":"synapse_pyspark"},"microsoft":{"language":"python","ms_spell_check":{"ms_spell_check_language":"en"},"language_group":"synapse_pyspark"},"widgets":{},"kernelspec":{"name":"synapse_pyspark","language":"Python","display_name":"Synapse PySpark"},"nteract":{"version":"nteract-front-end@1.0.0"},"synapse_widget":{"version":"0.1","state":{}},"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}},"dependencies":{"lakehouse":{"default_lakehouse":"687e05cf-8840-4913-9a9c-8c7410077e44","default_lakehouse_name":"Earthquake_lakehouse","default_lakehouse_workspace_id":"5ec706af-e96b-4e56-9a4c-1ece690359ff"}}},"nbformat":4,"nbformat_minor":5}